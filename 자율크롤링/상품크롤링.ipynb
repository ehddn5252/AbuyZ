{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Œ ìƒí’ˆ ì •ë³´ í¬ë¡¤ë§  \n",
    "* urllib ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ ìƒí’ˆ í˜ì´ì§€ ëª©ë¡ ë°›ì•„ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì½ì–´ë“¤ì´ê¸°\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# íŒŒì¼ ì£¼ì†Œ í¬ë¡¤ë§\n",
    "def bs_parsing(url):\n",
    "  response = requests.get(root_url + url)\n",
    "  soup = bs(response.text, \"html.parser\")\n",
    "  elements = soup.select(\"table#flisttable td > a\")\n",
    "  \n",
    "  # ì£¼ì†Œ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
    "  page_list = []\n",
    "  \n",
    "  # ìƒì„¸ í˜ì´ì§€ ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸í™”\n",
    "  for (idx, el) in enumerate(elements, 1):\n",
    "    page_list.append(root_url + el.attrs[\"href\"].replace(\"%2F\", \"/\"))\n",
    "    \n",
    "  return page_list\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ ê°’ì„ txt íŒŒì¼ì— í•œ ì¤„ì”© ì €ì¥\n",
    "def save_text_file(page_list):\n",
    "  f = open(\"C:/Users/sodud/study/ssafy_spec_pjt/subtitle/data/page_url_list.txt\", \"w\", encoding=\"UTF8\")\n",
    "  for page in page_list:\n",
    "    f.write(page)\n",
    "    f.write(\"\\n\")\n",
    "  f.close\n",
    "  (\"[SUCCESS] ìë§‰ í˜ì´ì§€ ëª©ë¡ ì €ì¥\")\n",
    "\n",
    "# ìë§‰ ì‚¬ì´íŠ¸\n",
    "root_url = \"https://kitsunekko.net\"\n",
    "\n",
    "# ì¼ë³¸ì–´ ìë§‰ ëª©ë¡ í˜ì´ì§€\n",
    "page_url = \"/dirlist.php?dir=subtitles/japanese/\"\n",
    "\n",
    "# ìë§‰ í˜ì´ì§€ ëª©ë¡ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
    "page_list = bs_parsing(page_url)\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥\n",
    "save_text_file(page_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ ìƒí’ˆ ì •ë³´ ì—‘ì…€ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook(write_only=True)\n",
    "ws = wb.create_sheet('ìƒí’ˆì •ë³´')\n",
    "# ì»¬ëŸ¼ ëª…\n",
    "ws.append([ 'ì´ë¦„', 'ê°€ê²©', 'ì„¤ëª… ì´ë¯¸ì§€', 'ì›ì‚°ì§€', 'ìƒí’ˆ ìƒíƒœ', 'ìƒì‚°ì&ìˆ˜ì…ì', 'í• ì¸ìœ¨', 'ë¦¬ë·° í‰ì ', 'ë°°ì†¡ë£Œ', 'ìƒí’ˆì‚¬ì§„1','ìƒí’ˆì‚¬ì§„2','ìƒí’ˆì‚¬ì§„3'])\n",
    "\n",
    "# ì„ì‹œ url\n",
    "temp_url= \"https://www.lotteon.com/p/product/LO1987818462?areaCode=AD_CPC&entryPoint=ad&dp_infw_cd=CASFC01200000&clickId=C33295679634\"\n",
    "\n",
    "\n",
    "# ì›¹ ì„œë²„ì— ìš”ì²­í•˜ê¸°\n",
    "# res = requests.get(temp_url)\n",
    "# res.raise_for_status()\n",
    "\n",
    "\n",
    "webpage = requests.get(\"https://www.lotteon.com/p/product/LO1987818462?areaCode=AD_CPC&entryPoint=ad&dp_infw_cd=CASFC01200000&clickId=C33295679634\")\n",
    "soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "temp = soup.select(\"div.productName\")\n",
    "temp2 = soup.select('.productName')\n",
    "print(temp)\n",
    "print(temp2)\n",
    "temp3 = soup.find('div',class_ = 'productName')\n",
    "print(temp3)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#     product_name = web_html.select_one('.productName').get_text()\n",
    "#     upload_data = web_html.select('.top_cell__3DnEV em')[2].get_text()\n",
    "#     average_grade = web_html.find(class_=\"top_grade__3jjdl\").get_text()[2:5]\n",
    "#     low_price = web_html.select('.productList_price__2FKhU em')[0].get_text()\n",
    "#     high_price = web_html.select('.productList_price__2FKhU em')[-1].get_text()\n",
    "#     five_point = web_html.select('.filter_top_list__3rOdK em')[1].get_text()[1:-1]\n",
    "#     four_point = web_html.select('.filter_top_list__3rOdK em')[2].get_text()[1:-1]\n",
    "#     three_point = web_html.select('.filter_top_list__3rOdK em')[3].get_text()[1:-1]\n",
    "#     two_point = web_html.select('.filter_top_list__3rOdK em')[4].get_text()[1:-1]\n",
    "#     one_point = web_html.select('.filter_top_list__3rOdK em')[5].get_text()[1:-1]\n",
    "    \n",
    "# print(web_html.find_all('.productName'))\n",
    "\n",
    "# soup ê°ì²´ ë§Œë“¤ê¸°\n",
    "# soup = BeautifulSoup(temp_url, \"html.parser\")\n",
    "# temp = soup.select(\"div\", class_=\".productName\")\n",
    "# print(temp)\n",
    "\n",
    "\n",
    "\n",
    "# product_name = web_html.select_one('h2').children.get_text()\n",
    "# product_price = web_html.select_one('h2').children.get_text()\n",
    "# des_picture = web_html.select_one('h2').children.get_text()\n",
    "# origin = web_html.select_one('h2').children.get_text()\n",
    "# status = web_html.select_one('h2').children.get_text()\n",
    "# producer = web_html.select_one('h2').children.get_text()\n",
    "# discount_rate = web_html.select_one('h2').children.get_text()\n",
    "# review_rating = web_html.select_one('h2').children.get_text()\n",
    "# delivery_fee = web_html.select_one('h2').children.get_text()\n",
    "# product_thumbnail_1 = web_html.select_one('h2').children.get_text()\n",
    "# product_thumbnail_2 = web_html.select_one('h2').children.get_text()\n",
    "# product_thumbnail_3 = web_html.select_one('h2').children.get_text()\n",
    "    \n",
    "    \n",
    "\n",
    "# ws.append([product_name, product_price, des_picture, origin, status, producer, discount_rate, review_rating, delivery_fee, product_thumbnail_1, product_thumbnail_2, product_thumbnail_3 ])\n",
    "\n",
    "\n",
    "# wb.save('ìƒí’ˆì •ë³´.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ìœ„: ì°¸êµìœ¡-103í™”\n",
      "2ìœ„: í€˜ìŠ¤íŠ¸ì§€ìƒì£¼ì˜-54í™” ê°€ì¡± ê±´ë“¤ë©´ ë’¤ì§„ë‹¤ê³ \n",
      "3ìœ„: ìœˆë“œë¸Œë ˆì´ì»¤-4ë¶€ - 34í™” ë§ˆìŒì˜ í‰ì˜¨\n",
      "4ìœ„: ë·°í‹°í’€ êµ°ë°”ë¦¬-352í™”_ì†Œìˆ˜ë¡œì„œ ì²« ì‹œìœ„ (2)\n",
      "5ìœ„: ì‹ í™”ê¸‰ ê·€ì† ì•„ì´í…œì„ ì†ì— ë„£ì—ˆë‹¤-22í™”\n",
      "6ìœ„: íŒ”ì´í”¼í”Œ-55í™” - ê³„ëª¨ì„ì˜ í–¥ë°©\n",
      "7ìœ„: ì¥ì”¨ì„¸ê°€ í˜¸ìœ„ë¬´ì‚¬-181í™”\n",
      "8ìœ„: ë²„ë¦¼ë°›ì€ ì™•ë…€ì˜ ì€ë°€í•œ ì¹¨ì‹¤-18í™”. í•œë°¤ì˜ ìŠµê²©ì\n",
      "9ìœ„: ì‹¸ì›€ë…í•™-151í™” : ë³´ë¯¸ ë³´ê³  ì‹¶ë‹¤\n",
      "10ìœ„: ë¦¬í„´ íˆ¬ í”Œë ˆì´ì–´-100í™”. ì•½ì† (2)\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„í•˜ê¸°\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =\"https://comic.naver.com/webtoon/weekday\"\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°\n",
    "filename = \"ë„¤ì´ë²„ ì›¹íˆ° ì¸ê¸° ìˆœìœ„.csv\"\n",
    "f = open(filename, \"w\", encoding=\"utf-8-sig\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "columns_name = [\"ìˆœìœ„\", \"ì›¹íˆ°ëª…\"] # ì»¬ëŸ¼ ì†ì„±ëª… ë§Œë“¤ê¸°\n",
    "\n",
    "writer.writerow(columns_name)\n",
    "\n",
    "# ì›¹ ì„œë²„ì— ìš”ì²­í•˜ê¸°\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "# soup ê°ì²´ ë§Œë“¤ê¸°\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "cartoonsBox = soup.find('ol', attrs={\"class\": \"asideBoxRank\"}) # ì „ì²´ ì˜ì—­ì—ì„œ 'a' íƒœê·¸ë¥¼ ì°¾ì§€ ì•Šê³  ì¸ê¸° ê¸‰ìƒìŠ¹ ì˜ì—­ìœ¼ë¡œ ë²”ìœ„ ì œí•œ\n",
    "cartoons = cartoonsBox.find_all('a') # ì¸ê¸° ê¸‰ìƒìŠ¹ ì˜ì—­ì—ì„œ 'a'íƒœê·¸ ëª¨ë‘ ì°¾ì•„ ë³€ìˆ˜ cartoonsì— í• ë‹¹\n",
    "\n",
    "i = 1\n",
    "\n",
    "# ë°˜ë³µë¬¸ìœ¼ë¡œ ì œëª© ê°€ì ¸ì˜¤ê¸°(í„°ë¯¸ë„ ì°½ ì¶œë ¥ ë° ì—‘ì…€ ì €ì¥)\n",
    "for cartoon in cartoons: \n",
    "  title = cartoon.get(\"title\") \n",
    "  print(f\"{str(i)}ìœ„: {title}\")\n",
    "  data = [str(i), title]\n",
    "  writer.writerow(data)\n",
    "  i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "eebaf1173d8d9c3c4ee9a7b8bb1432a7f576348d6cb7a26bc263375fbc310797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
